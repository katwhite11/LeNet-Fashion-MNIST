{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Statements"
      ],
      "metadata": {
        "id": "smEzgSEhyzMZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nt18cMedV3p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Parameters Function"
      ],
      "metadata": {
        "id": "_3LbIBUqy33g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "XNky7RvReSCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "qZuVB0gheioi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "\n",
        "# Create data loader\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Load one batch of training data\n",
        "for data in train_dataloader:\n",
        "  break\n",
        "\n",
        "  x = data[0]\n",
        "  y = data[1]\n",
        "  print(\"Shape of x [N, C, H, W]:\", x.shape)\n",
        "  print(\"Shape of y:\", y.shape)\n",
        "\n",
        "  plt.figure(figsize=(8,10))\n",
        "  for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.imshow(x[i,0,:,:], cmap=\"gray\")\n",
        "    plt.title(\"Label:%i\" %y[i])\n",
        "    "
      ],
      "metadata": {
        "id": "TZeJpdRXfDOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LeNet Model"
      ],
      "metadata": {
        "id": "dSPsUnrMlais"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, \n",
        "                  out_channels=6, \n",
        "                  kernel_size=5, \n",
        "                  stride=1, \n",
        "                  padding=2),\n",
        "        nn.Sigmoid(),\n",
        "        nn.AvgPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=6,  # This number must be the same as the output of the previous layer\n",
        "                  out_channels=16, \n",
        "                  kernel_size=5, \n",
        "                  stride=1, \n",
        "                  padding=0),\n",
        "        nn.Sigmoid(), #ReLU is better\n",
        "        nn.AvgPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(16*5*5, 120),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.Linear(120, 84),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    logits = self.fc3(x)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "I1zPY2-Plcdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Function"
      ],
      "metadata": {
        "id": "cDFrNc6_yjzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "  model.train() # set model to train model\n",
        "  for step, (x, y) in enumerate(dataloader): \n",
        "    # send data to GPU or CPU\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    \n",
        "    # feed the data to the model\n",
        "    pred = model(x)\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = loss_fn(pred, y)\n",
        "    \n",
        "    # backpropagation (update the parameters)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if step % 200 == 0: \n",
        "      loss  = loss.item()\n",
        "      print('Current Step: %d, loss:%.4f' %(step, loss))"
      ],
      "metadata": {
        "id": "J36jf-ewg2kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test Function"
      ],
      "metadata": {
        "id": "pu6yRYXjyorv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn, device):\n",
        "  num_batch = len(dataloader)\n",
        "\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      pred = model(x)\n",
        "      loss = loss_fn(pred, y)\n",
        "      test_loss += loss.item()\n",
        "      \n",
        "      y_hat = pred.argmax(1)\n",
        "      correct_batch = (y_hat == y).type(torch.float).sum().item()\n",
        "      correct += correct_batch\n",
        "  test_loss /= num_batch\n",
        "  correct = correct / (num_batch * batch_size)\n",
        "\n",
        "  print(\"Test Accuracy:%.4f\" % correct)"
      ],
      "metadata": {
        "id": "rlORAGTvhF-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the Model"
      ],
      "metadata": {
        "id": "GgvWYXVVyZvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get CPU or GPU for the training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create the model\n",
        "model = LeNet().to(device)\n",
        "print(\"---------------\\nTraining the LeNet model\")\n",
        "print(\"Total number of trainable parameters:%d \\n------------\" %count_parameters(model))\n",
        "print(model)\n",
        "\n",
        "# Optimizing the model parameter\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Train model in epochs\n",
        "epochs = 5\n",
        "for t in tqdm.tqdm(range(epochs)):\n",
        "  print('Epoch %d \\n----------------' %t)\n",
        "  train(train_dataloader, model, loss_fn, optimizer, device)\n",
        "  test(test_dataloader, model, loss_fn, device)\n",
        "print(\"Done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7-dNOePtmoB",
        "outputId": "52feb5d9-5086-421d-a8aa-77ab7f34b625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------\n",
            "Training the LeNet model\n",
            "Total number of trainable parameters:61706 \n",
            "------------\n",
            "LeNet(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Sigmoid()\n",
            "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): Sigmoid()\n",
            "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 \n",
            "----------------\n",
            "Current Step: 0, loss:2.3852\n",
            "Current Step: 200, loss:2.3089\n",
            "Current Step: 400, loss:2.3050\n",
            "Current Step: 600, loss:2.3137\n",
            "Current Step: 800, loss:2.2859\n",
            "Current Step: 1000, loss:2.3146\n",
            "Current Step: 1200, loss:2.3026\n",
            "Current Step: 1400, loss:2.2905\n",
            "Current Step: 1600, loss:2.2961\n",
            "Current Step: 1800, loss:2.3108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:26<01:44, 26.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.0998\n",
            "Epoch 1 \n",
            "----------------\n",
            "Current Step: 0, loss:2.2929\n",
            "Current Step: 200, loss:2.3089\n",
            "Current Step: 400, loss:2.3049\n",
            "Current Step: 600, loss:2.3137\n",
            "Current Step: 800, loss:2.2861\n",
            "Current Step: 1000, loss:2.3146\n",
            "Current Step: 1200, loss:2.3026\n",
            "Current Step: 1400, loss:2.2906\n",
            "Current Step: 1600, loss:2.2961\n",
            "Current Step: 1800, loss:2.3107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:51<01:17, 25.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.0998\n",
            "Epoch 2 \n",
            "----------------\n",
            "Current Step: 0, loss:2.2929\n",
            "Current Step: 200, loss:2.3089\n",
            "Current Step: 400, loss:2.3048\n",
            "Current Step: 600, loss:2.3137\n",
            "Current Step: 800, loss:2.2862\n",
            "Current Step: 1000, loss:2.3146\n",
            "Current Step: 1200, loss:2.3027\n",
            "Current Step: 1400, loss:2.2907\n",
            "Current Step: 1600, loss:2.2962\n",
            "Current Step: 1800, loss:2.3106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [01:16<00:50, 25.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.0998\n",
            "Epoch 3 \n",
            "----------------\n",
            "Current Step: 0, loss:2.2929\n",
            "Current Step: 200, loss:2.3089\n",
            "Current Step: 400, loss:2.3047\n",
            "Current Step: 600, loss:2.3137\n",
            "Current Step: 800, loss:2.2864\n",
            "Current Step: 1000, loss:2.3146\n",
            "Current Step: 1200, loss:2.3027\n",
            "Current Step: 1400, loss:2.2908\n",
            "Current Step: 1600, loss:2.2963\n",
            "Current Step: 1800, loss:2.3105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [01:41<00:25, 25.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.0998\n",
            "Epoch 4 \n",
            "----------------\n",
            "Current Step: 0, loss:2.2929\n",
            "Current Step: 200, loss:2.3089\n",
            "Current Step: 400, loss:2.3046\n",
            "Current Step: 600, loss:2.3137\n",
            "Current Step: 800, loss:2.2866\n",
            "Current Step: 1000, loss:2.3146\n",
            "Current Step: 1200, loss:2.3027\n",
            "Current Step: 1400, loss:2.2909\n",
            "Current Step: 1600, loss:2.2963\n",
            "Current Step: 1800, loss:2.3105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [02:09<00:00, 25.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:0.0998\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}